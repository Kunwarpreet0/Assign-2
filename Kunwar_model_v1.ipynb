{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the liberaries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID Diagnosis  Mean Radius  Mean Texture  Mean Perimeter  Mean Area  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   Mean Smoothness  Mean Compactness  Mean Concavity  Mean Concave Points  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  Largest Radius  Largest Texture  Largest Perimeter  Largest Area  \\\n",
      "0  ...           25.38            17.33             184.60        2019.0   \n",
      "1  ...           24.99            23.41             158.80        1956.0   \n",
      "2  ...           23.57            25.53             152.50        1709.0   \n",
      "3  ...           14.91            26.50              98.87         567.7   \n",
      "4  ...           22.54            16.67             152.20        1575.0   \n",
      "\n",
      "   Largest Smoothness  Largest Compactness  Largest Concavity  \\\n",
      "0              0.1622               0.6656             0.7119   \n",
      "1              0.1238               0.1866             0.2416   \n",
      "2              0.1444               0.4245             0.4504   \n",
      "3              0.2098               0.8663             0.6869   \n",
      "4              0.1374               0.2050             0.4000   \n",
      "\n",
      "   Largest Concave Points  Largest Symmetry  Largest Fractal Dimension  \n",
      "0                  0.2654            0.4601                    0.11890  \n",
      "1                  0.1860            0.2750                    0.08902  \n",
      "2                  0.2430            0.3613                    0.08758  \n",
      "3                  0.2575            0.6638                    0.17300  \n",
      "4                  0.1625            0.2364                    0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load and Preprocess the Data\n",
    "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "column_names = [\"ID\", \"Diagnosis\", \"Mean Radius\", \"Mean Texture\", \"Mean Perimeter\", \"Mean Area\",\n",
    "                \"Mean Smoothness\", \"Mean Compactness\", \"Mean Concavity\", \"Mean Concave Points\",\n",
    "                \"Mean Symmetry\", \"Mean Fractal Dimension\", \"SE Radius\", \"SE Texture\", \"SE Perimeter\",\n",
    "                \"SE Area\", \"SE Smoothness\", \"SE Compactness\", \"SE Concavity\", \"SE Concave Points\",\n",
    "                \"SE Symmetry\", \"SE Fractal Dimension\", \"Largest Radius\", \"Largest Texture\",\n",
    "                \"Largest Perimeter\", \"Largest Area\", \"Largest Smoothness\", \"Largest Compactness\",\n",
    "                \"Largest Concavity\", \"Largest Concave Points\", \"Largest Symmetry\", \"Largest Fractal Dimension\"]\n",
    "df = pd.read_csv(data_url, header=None, names=column_names)\n",
    "# printing head\n",
    "print(df.head())\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(\"ID\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop(\"Diagnosis\", axis=1)\n",
    "y = df[\"Diagnosis\"]\n",
    "\n",
    "# Split the Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.9397590361445783\n",
      "Predicted Diagnosis: ['B']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the Model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Training the Model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#  Evaluating the Model\n",
    "y_pred = model.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=\"M\")\n",
    "\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# Make Predictions\n",
    "new_data = [[14.26, 19.65, 97.83, 629.9, 0.07837, 0.2233, 0.3003, 0.07798, 0.1704, 0.07769,\n",
    "             0.2998, 0.9413, 1.752, 22.15, 0.004407, 0.02675, 0.03119, 0.007259, 0.01482,\n",
    "             0.003528, 15.3, 23.73, 107.0, 709.0, 0.08949, 0.4193, 0.6783, 0.1505, 0.2398,\n",
    "             0.1082]]\n",
    "prediction = model.predict(new_data)\n",
    "\n",
    "print(\"Predicted Diagnosis:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
